{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1） Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://huggingface.co/datasets/YuAnthony/tnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaModel\n",
    "\n",
    "# from transformers import BertPreTrainedModel, BertConfig, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config():\n",
    "    train_data_path = './tnews/train.json'\n",
    "    dev_data_path = './tnews/dev.json'\n",
    "    test_data_path = './tnews/test.json'\n",
    "    label_data_path = './tnews/labels.json'\n",
    "    bert_name = \"hfl/chinese-roberta-wwm-ext\"\n",
    "    max_length  = 60\n",
    "    batch_size = 8\n",
    "    epochs = 20\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    do_acc = False\n",
    "    do_recall = False\n",
    "    do_precision = False\n",
    "    do_f1 = False\n",
    "    print_report = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data(config,data_type='train',nums_sample = -1):\n",
    "    text = []\n",
    "    label = []\n",
    "    data_path = {\"train\":config.train_data_path,\n",
    "                \"dev\":config.dev_data_path,\n",
    "                \"test\":config.test_data_path}[data_type]\n",
    "    with open(data_path, encoding='utf-8')as file:\n",
    "        for line in file.readlines()[:nums_sample]:\n",
    "            line = line.strip()\n",
    "            dic = json.loads(line)\n",
    "            text.append(dic['sentence'])\n",
    "            label.append(dic['label'])\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['text'] = text\n",
    "    df['label'] = label\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_dict(config):\n",
    "    label_dict = {}\n",
    "    with open(config.label_data_path, encoding='utf-8')as file:\n",
    "        for line in file.readlines():\n",
    "            line = line.strip()\n",
    "            dic = json.loads(line)\n",
    "            label_dict[dic['label']]=dic['label_desc']\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_raw_data(config,\"train\",512)\n",
    "df_dev = get_raw_data(config,\"dev\",100)\n",
    "labels_dict = get_labels_dict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>上课时学生手机响个不停，老师一怒之下把手机摔了，家长拿发票让老师赔，大家怎么看待这种事？</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>商赢环球股份有限公司关于延期回复上海证券交易所对公司2017年年度报告的事后审核问询函的公告</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>通过中介公司买了二手房，首付都付了，现在卖家不想卖了。怎么处理？</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018年去俄罗斯看世界杯得花多少钱？</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>剃须刀的个性革新，雷明登天猫定制版新品首发</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text label\n",
       "0    上课时学生手机响个不停，老师一怒之下把手机摔了，家长拿发票让老师赔，大家怎么看待这种事？   108\n",
       "1  商赢环球股份有限公司关于延期回复上海证券交易所对公司2017年年度报告的事后审核问询函的公告   104\n",
       "2                通过中介公司买了二手房，首付都付了，现在卖家不想卖了。怎么处理？   106\n",
       "3                             2018年去俄罗斯看世界杯得花多少钱？   112\n",
       "4                           剃须刀的个性革新，雷明登天猫定制版新品首发   109"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100': 'news_story',\n",
       " '101': 'news_culture',\n",
       " '102': 'news_entertainment',\n",
       " '103': 'news_sports',\n",
       " '104': 'news_finance',\n",
       " '106': 'news_house',\n",
       " '107': 'news_car',\n",
       " '108': 'news_edu',\n",
       " '109': 'news_tech',\n",
       " '110': 'news_military',\n",
       " '112': 'news_travel',\n",
       " '113': 'news_world',\n",
       " '114': 'news_stock',\n",
       " '115': 'news_agriculture',\n",
       " '116': 'news_game'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Process Data According to Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.bert_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dic = {'100': '民生', '101': '文化', '102': '娱乐', '103': '体育', '104': '财经', '106': '房产', '107': '汽车',\n",
    "                          '108': '教育', '109': '科技', '110': '军事', '112': '旅游', '113': '国际', '114': '证券', '115': '农业',\n",
    "                          '116': '游戏'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = {k: i for i, (k, v) in enumerate(label_dic.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx_dic = {k: tokenizer.convert_tokens_to_ids(list(v)) for k, v in label_dic.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100': [3696, 4495],\n",
       " '101': [3152, 1265],\n",
       " '102': [2031, 727],\n",
       " '103': [860, 5509],\n",
       " '104': [6568, 5307],\n",
       " '106': [2791, 772],\n",
       " '107': [3749, 6756],\n",
       " '108': [3136, 5509],\n",
       " '109': [4906, 2825],\n",
       " '110': [1092, 752],\n",
       " '112': [3180, 3952],\n",
       " '113': [1744, 7354],\n",
       " '114': [6395, 1171],\n",
       " '115': [1093, 689],\n",
       " '116': [3952, 2767]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_idx_dic #these tokens to fill prompt tempalte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_length(text):\n",
    "    encoding = tokenizer(text)\n",
    "    return len(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>上课时学生手机响个不停，老师一怒之下把手机摔了，家长拿发票让老师赔，大家怎么看待这种事？</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>商赢环球股份有限公司关于延期回复上海证券交易所对公司2017年年度报告的事后审核问询函的公告</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>通过中介公司买了二手房，首付都付了，现在卖家不想卖了。怎么处理？</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018年去俄罗斯看世界杯得花多少钱？</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>剃须刀的个性革新，雷明登天猫定制版新品首发</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text label\n",
       "0    上课时学生手机响个不停，老师一怒之下把手机摔了，家长拿发票让老师赔，大家怎么看待这种事？   108\n",
       "1  商赢环球股份有限公司关于延期回复上海证券交易所对公司2017年年度报告的事后审核问询函的公告   104\n",
       "2                通过中介公司买了二手房，首付都付了，现在卖家不想卖了。怎么处理？   106\n",
       "3                             2018年去俄罗斯看世界杯得花多少钱？   112\n",
       "4                           剃须刀的个性革新，雷明登天猫定制版新品首发   109"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_len_list = df_train['text'].apply(lambda x:get_token_length(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 23.,  47.,  96.,  86.,  98., 101.,  46.,   8.,   2.,   5.]),\n",
       " array([ 7. , 11.1, 15.2, 19.3, 23.4, 27.5, 31.6, 35.7, 39.8, 43.9, 48. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(token_len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_ids(text):\n",
    "    encoding = tokenizer(text = text,\n",
    "                         max_length = config.max_length,\n",
    "                         padding=\"max_length\",\n",
    "                         truncation=True,\n",
    "                         return_tensors = \"pt\",)\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MASK]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs_process(data_text, data_label):\n",
    "\n",
    "    prompt_template = '播报一则[MASK][MASK]新闻：'\n",
    "    mask_pos = [5, 6]\n",
    "\n",
    "    encodings = []\n",
    "    labels = []\n",
    "    for text, label in zip(data_text, data_label):\n",
    "        text = prompt_template + text # templata\n",
    "        encoding = get_token_ids(text)\n",
    "        encodings.append(encoding) \n",
    "        labels.append(label_index[label])\n",
    "\n",
    "    item = {}\n",
    "    for encoding in encodings:\n",
    "        for key in ['input_ids', 'attention_mask']:\n",
    "            if key in item.keys():\n",
    "                item[key].append(encoding[key])\n",
    "            else:\n",
    "                item[key] = [encoding[key]]\n",
    "\n",
    "    for key in ['input_ids', 'attention_mask']:\n",
    "        item[key] = torch.cat(item[key])\n",
    "        \n",
    "    return item, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(df):\n",
    "    text  = df['text']\n",
    "    label  = df['label']\n",
    "    \n",
    "    encoding, label = inputs_process(text, label)\n",
    "    \n",
    "    return DataLoader(Dataset(encoding, label), config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_data_loader(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_loader = get_data_loader(df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 60])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Test\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = label_idx_dic.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx_0, label_idx_1 = zip(*label_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Prompt Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Debug'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Debug\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = data['input_ids'].to(config.device)\n",
    "attention_mask = data['attention_mask'].to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 60])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers.models.bert.modeling_bert.BertModel\n",
    "from transformers import RobertaConfig, RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertOnlyMLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = RobertaConfig()\n",
    "bert = RobertaModel(configuration,add_pooling_layer=False).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_layer = BertOnlyMLMHead(configuration)  # MLM vocab multi-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = data['input_ids'].to(config.device)\n",
    "attention_mask = data['attention_mask'].to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = bert.to(config.device)\n",
    "cls_layer = cls_layer.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = cls_layer(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_logits = logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 60, 30522])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_logits_1 =  token_logits[:,mask_pos[0],:] # take the mask position [batch_size,vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_logits_2 = token_logits_1[:, label_idx_0] # [batch_size,score of corresponding values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_logits = token_logits[:, mask_pos[0]][:, label_idx_0] + \\\n",
    "            token_logits[:,mask_pos[1]][:, label_idx_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pos = [5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0649,  0.8618,  0.5800,  ..., -0.1845, -0.1193,  0.8773],\n",
       "        [-0.7712,  0.4287,  0.0941,  ..., -0.1884,  0.5348,  0.2472],\n",
       "        [-0.1336,  0.5467,  0.8326,  ...,  0.1663,  0.4030,  0.3776],\n",
       "        ...,\n",
       "        [-0.1685,  0.6121,  0.2482,  ..., -0.4368,  0.1812, -0.1295],\n",
       "        [-0.3379,  0.3610,  0.2945,  ...,  0.0212,  0.6105, -0.1500],\n",
       "        [-0.5605,  0.5784, -0.0747,  ...,  0.4578,  0.5981,  0.2168]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits[:, mask_pos[0]][:,[0:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0649, -0.7712, -0.1336, -0.6649, -0.4029, -0.1685, -0.3379, -0.5605],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits[:, mask_pos[0]][:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0649,  0.8618],\n",
       "        [-0.7712,  0.4287],\n",
       "        [-0.1336,  0.5467],\n",
       "        [-0.6649,  0.6610],\n",
       "        [-0.4029,  0.4836],\n",
       "        [-0.1685,  0.6121],\n",
       "        [-0.3379,  0.3610],\n",
       "        [-0.5605,  0.5784]], device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits[:, mask_pos[0]][:,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1047493638.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [53]\u001b[1;36m\u001b[0m\n\u001b[1;33m    [:, label_idx_0]\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[:, label_idx_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_logits = token_logits[:, mask_pos[0]][:, label_idx_0] + \\\n",
    "    token_logits[:, mask_pos[1]][:, label_idx_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 60, 768])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 4.1580e-01, -9.1603e-01,  8.6591e-02,  ...,  1.1301e-01,\n",
       "           5.7214e-01,  9.4964e-01],\n",
       "         [ 1.2901e+00, -6.8629e-01, -3.2986e-01,  ...,  5.2748e-01,\n",
       "           2.4873e-01,  4.3296e-01],\n",
       "         [-1.1646e+00, -8.0976e-01, -5.6755e-01,  ..., -2.5062e-01,\n",
       "          -1.3998e+00,  7.0954e-01],\n",
       "         ...,\n",
       "         [-3.1455e-01, -3.4643e-02,  5.7883e-01,  ...,  1.3990e+00,\n",
       "          -8.5608e-01,  1.1558e-01],\n",
       "         [-1.1999e+00,  4.5291e-01, -6.8696e-01,  ...,  5.4611e-01,\n",
       "           2.8636e-01,  9.4848e-02],\n",
       "         [-1.2895e+00,  3.3704e-01, -1.7707e+00,  ...,  1.2694e+00,\n",
       "          -5.2734e-01,  6.4019e-01]],\n",
       "\n",
       "        [[-4.1272e-01, -1.5621e+00,  2.1502e-01,  ...,  2.1669e+00,\n",
       "           2.3557e-02,  6.8620e-01],\n",
       "         [ 6.4791e-01, -7.9876e-01,  2.1138e-01,  ...,  7.3984e-01,\n",
       "           7.4993e-01,  8.2055e-01],\n",
       "         [-1.6781e+00, -9.3270e-01, -7.6341e-01,  ...,  1.7413e-01,\n",
       "          -6.0170e-01,  4.7445e-01],\n",
       "         ...,\n",
       "         [-5.1532e-01, -2.3135e-01,  1.1984e+00,  ...,  1.6254e+00,\n",
       "          -4.2027e-01,  5.4044e-01],\n",
       "         [-1.0081e+00,  4.2998e-01, -7.9583e-01,  ...,  1.7151e+00,\n",
       "          -1.2254e+00,  7.7745e-01],\n",
       "         [-4.0190e-01,  7.9370e-02, -4.8455e-01,  ...,  8.5339e-01,\n",
       "          -4.2523e-01,  1.5630e-01]],\n",
       "\n",
       "        [[ 2.5720e-02, -7.1620e-01,  1.2807e-01,  ...,  2.0479e+00,\n",
       "          -5.3883e-02,  7.0746e-01],\n",
       "         [ 3.7992e-01, -1.4910e+00, -3.4063e-01,  ...,  6.7016e-01,\n",
       "           8.7667e-02,  4.2722e-01],\n",
       "         [-1.1715e+00, -1.6040e+00,  8.1327e-02,  ...,  5.4042e-01,\n",
       "          -1.5934e-01, -4.2535e-01],\n",
       "         ...,\n",
       "         [-3.2009e-01, -7.6654e-01,  3.6570e-01,  ...,  9.8108e-01,\n",
       "          -1.7939e-01,  4.4327e-01],\n",
       "         [ 2.6299e-01,  3.9497e-01, -6.8594e-01,  ...,  9.9280e-01,\n",
       "          -3.8988e-01, -7.8534e-03],\n",
       "         [-5.5807e-01, -6.0110e-01, -9.5875e-01,  ...,  8.5501e-01,\n",
       "           6.2078e-01,  7.8164e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-4.8989e-01, -8.1302e-01,  3.7825e-01,  ...,  2.1093e+00,\n",
       "          -1.7663e-01,  1.4578e+00],\n",
       "         [ 2.7875e-01, -9.1682e-01,  3.5263e-02,  ..., -1.9412e-01,\n",
       "           3.4544e-01,  2.5605e-01],\n",
       "         [-6.2382e-01, -1.1511e+00, -3.5941e-01,  ...,  5.3785e-01,\n",
       "          -1.3354e+00,  5.2157e-02],\n",
       "         ...,\n",
       "         [-5.9944e-02, -9.5555e-02,  3.7534e-01,  ...,  1.8113e+00,\n",
       "          -2.8028e-01,  1.0409e+00],\n",
       "         [-2.0554e-01,  5.3301e-02, -4.0516e-01,  ...,  1.1863e+00,\n",
       "          -3.8486e-01, -3.1259e-01],\n",
       "         [-1.0248e+00, -9.5581e-02, -1.2525e-01,  ...,  1.8963e+00,\n",
       "          -1.0069e+00,  5.6689e-01]],\n",
       "\n",
       "        [[ 1.6013e-01, -1.0771e+00,  4.8610e-01,  ...,  1.7582e+00,\n",
       "          -5.1507e-01,  2.0671e-01],\n",
       "         [ 7.2918e-01, -3.1862e-01, -7.9297e-01,  ...,  3.9895e-01,\n",
       "           2.1312e-01,  9.5940e-01],\n",
       "         [-4.3423e-01, -6.2933e-01, -2.1038e-02,  ..., -1.4427e-01,\n",
       "          -1.2868e+00,  2.2704e-01],\n",
       "         ...,\n",
       "         [-5.0865e-01, -7.4322e-01,  7.2071e-01,  ...,  1.2416e+00,\n",
       "          -7.3266e-01,  3.3769e-01],\n",
       "         [-4.9740e-01,  2.0107e-01, -6.4636e-01,  ...,  1.0591e+00,\n",
       "           3.2042e-01, -8.6683e-01],\n",
       "         [-2.1363e-01, -6.9267e-01, -1.5504e-01,  ...,  2.2116e+00,\n",
       "          -3.4210e-01, -4.7320e-01]],\n",
       "\n",
       "        [[-5.1475e-01, -9.0936e-01,  7.4986e-01,  ...,  1.7534e+00,\n",
       "           4.4895e-01,  9.5857e-01],\n",
       "         [ 9.1150e-01, -5.9562e-01, -2.7222e-01,  ...,  9.6402e-01,\n",
       "           9.6596e-01,  5.9374e-02],\n",
       "         [-1.1598e+00, -3.6007e-01, -1.2931e-01,  ...,  5.0427e-01,\n",
       "          -1.3593e+00, -3.1380e-01],\n",
       "         ...,\n",
       "         [-5.4720e-01, -4.9286e-02,  3.2224e-01,  ...,  1.3427e+00,\n",
       "           3.1664e-01,  2.3192e-01],\n",
       "         [-6.8620e-01,  4.9115e-01, -4.6544e-01,  ...,  1.5012e+00,\n",
       "          -9.6665e-04, -1.6924e-02],\n",
       "         [-6.0904e-01,  2.8397e-01, -1.6589e+00,  ...,  1.1990e+00,\n",
       "           8.0265e-02,  9.2819e-01]]], device='cuda:0',\n",
       "       grad_fn=<NativeLayerNormBackward>), pooler_output=None, hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3183954656.py, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [45]\u001b[1;36m\u001b[0m\n\u001b[1;33m    outputs = self.bert(\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class BertForPromptTuning(BertPreTrainedModel):\n",
    "    def __init__(self, config: BertConfig, prompt_index):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        \n",
    "        self.bert = RobertaModel(config, add_pooling_layer=False)  # backbone\n",
    "        self.cls = BertOnlyMLMHead(config)  # MLM vocab multi-classification\n",
    "        self.init_weights()\n",
    "    \n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        \"\"\"Use word embedding weight as the output weight in the cls layer\"\"\"\n",
    "        self.cls.predictions.decoder.weight = new_embeddings.weight\n",
    "        \n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids=None,\n",
    "            attention_mask=None,\n",
    "            token_type_ids=None,\n",
    "            position_ids=None,\n",
    "            head_mask=None,\n",
    "            inputs_embeds=None,\n",
    "            labels=None,\n",
    "            output_attentions=None,\n",
    "            output_hidden_states=None,\n",
    "            return_dict=None):\n",
    "        \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        \n",
    "        self.set_output_embeddings(self.bert.embeddings.word_embeddings)\n",
    "\n",
    "            outputs = self.bert(\n",
    "            input_ids=None,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict)\n",
    "\n",
    "        # outputs[0] -> shape [batch_size,max_length,hidden_size (768)]\n",
    "        logits = self.cls(outputs[0])\n",
    "        \n",
    "        # logits:  -> shape [batch_size,max_length,vocab_size]\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            s = attention_mask.shape[0] * attention_mask.shape[1]\n",
    "            loss = loss_fct(logits.view(s, -1), labels.view(-1))\n",
    "\n",
    "        # logits: tokens out-> [batch_size,max_length,vocab_size]\n",
    "        # pool out: outputs[1:] -> [batch_size,max_length,hidden_size]\n",
    "        # cls : outputs[0][:, 0] -> first token cls output [batch_size,hidden_size]\n",
    "        output = (logits,) + outputs[1:] + (outputs[0][:, 0],)\n",
    "        return ((loss,) + output) if loss is not None else output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids = input_ids,attention_mask = attention_mask,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100': [3696, 4495],\n",
       " '101': [3152, 1265],\n",
       " '102': [2031, 727],\n",
       " '103': [860, 5509],\n",
       " '104': [6568, 5307],\n",
       " '106': [2791, 772],\n",
       " '107': [3749, 6756],\n",
       " '108': [3136, 5509],\n",
       " '109': [4906, 2825],\n",
       " '110': [1092, 752],\n",
       " '112': [3180, 3952],\n",
       " '113': [1744, 7354],\n",
       " '114': [6395, 1171],\n",
       " '115': [1093, 689],\n",
       " '116': [3952, 2767]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_idx_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx_0, label_idx_1 = zip(*label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4495,\n",
       " 1265,\n",
       " 727,\n",
       " 5509,\n",
       " 5307,\n",
       " 772,\n",
       " 6756,\n",
       " 5509,\n",
       " 2825,\n",
       " 752,\n",
       " 3952,\n",
       " 7354,\n",
       " 1171,\n",
       " 689,\n",
       " 2767)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_idx_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3696,\n",
       " 3152,\n",
       " 2031,\n",
       " 860,\n",
       " 6568,\n",
       " 2791,\n",
       " 3749,\n",
       " 3136,\n",
       " 4906,\n",
       " 1092,\n",
       " 3180,\n",
       " 1744,\n",
       " 6395,\n",
       " 1093,\n",
       " 3952)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_idx_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
